<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-projects/zoomldm" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.2.1">
<title data-rh="true">ZoomLDM: Latent Diffusion Model for multi-scale image generation | Generative models for Histopatholgy</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://histodiffusion.github.io/img/histodiff-social-card-light.png"><meta data-rh="true" name="twitter:image" content="https://histodiffusion.github.io/img/histodiff-social-card-light.png"><meta data-rh="true" property="og:url" content="https://histodiffusion.github.io/docs/projects/zoomldm"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="ZoomLDM: Latent Diffusion Model for multi-scale image generation | Generative models for Histopatholgy"><meta data-rh="true" name="description" content="CVPR 2025"><meta data-rh="true" property="og:description" content="CVPR 2025"><link data-rh="true" rel="icon" href="/img/logo.png"><link data-rh="true" rel="canonical" href="https://histodiffusion.github.io/docs/projects/zoomldm"><link data-rh="true" rel="alternate" href="https://histodiffusion.github.io/docs/projects/zoomldm" hreflang="en"><link data-rh="true" rel="alternate" href="https://histodiffusion.github.io/docs/projects/zoomldm" hreflang="x-default"><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GQHJ36DQG7"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-GQHJ36DQG7",{anonymize_ip:!0})</script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="/assets/css/styles.56315523.css">
<script src="/assets/js/runtime~main.6ff36b86.js" defer="defer"></script>
<script src="/assets/js/main.ac7c4db6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/projects/pixcell">Projects</a><a href="https://github.com/cvlab-stonybrook" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://www3.cs.stonybrook.edu/~cvl/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">CVLab @ Stony Brook<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/projects/pixcell">Projects</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/projects/pixcell">PixCell - Generative foundation model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/projects/pathae">PathAE - Pathology image compression with autoencoders</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/projects/zoomldm">ZoomLDM - Multi-scale diffusion model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/projects/gensis">Gen-SIS - Generative augmentations for self-supervised learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/projects/infty_brush">∞-Brush - Large image synthesis in infinite dimensions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/projects/large_image">SSL-guided diffusion - Large image generation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/projects/pathldm">PathLDM: Text-conditioned pathology diffusion model</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Projects</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">ZoomLDM - Multi-scale diffusion model</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>ZoomLDM: Latent Diffusion Model for multi-scale image generation</h1>
<div class="container mt-5"><div class="card bg-light"><div class="card-body justify-content-center"><h2 class="card-title text-center">CVPR 2025</h2><h3 class="authors card-text text-center">Srikar Yellapragada*, Alexandros Graikos*, Kostas Triaridis,<br>
<!-- -->Prateek Prasanna, Rajarsi Gupta, Joel Saltz, Dimitris Samaras</h3><h3 class="authors card-text text-center">Stony Brook University</h3><div class="d-flex justify-content-center"><a href="https://github.com/cvlab-stonybrook/ZoomLDM/tree/main" target="_blank"><button class="paper_button">Code</button> </a><a href="https://arxiv.org/abs/2411.16969" target="_blank"><button class="paper_button">arXiv</button> </a><a href="/pages/zoomldm_large_images/large_images.html" target="_blank"><button class="paper_button">Large image viewer</button></a></div></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="tldr">TL;DR<a href="#tldr" class="hash-link" aria-label="Direct link to TL;DR" title="Direct link to TL;DR">​</a></h2>
<p>Using a diffusion model to generate <strong>digital pathology</strong> and <strong>satellite</strong> has been impractical due to their <strong>gigapixel sizes</strong>. Our previous works focused on generating small patches, which was limited to only capturing local context. Here we propose <strong>ZoomLDM</strong>, a <strong>multi-scale latent diffusion model</strong> that can synthesize large images in these domains. We introduce a novel magnification-aware conditioning mechanism that utilizes self-supervised learning (SSL) embeddings and allows the diffusion model to synthesize images at different &#x27;zoom&#x27; levels. Using the multi-scale nature of ZoomLDM we also propose an algorithm for computationally tractable and globally coherent <strong>image synthesis of up to 4096x4096 pixels</strong>, achieving unparalleled quality. Finally, we demonstrate that the multi-scale features extracted from ZoomLDM are highly effective in multiple instance learning tasks.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="model">Model<a href="#model" class="hash-link" aria-label="Direct link to Model" title="Direct link to Model">​</a></h2>
<p><img decoding="async" loading="lazy" alt="method_figure" src="/assets/images/method-775a5d041d4626acfed2a8e1ee9c3100.png" width="1903" height="741" class="img_ev3q"></p>
<p>We first extract 256 × 256 patches from large images at the initial scale (20× for pathology) and generate SSL embedding matrices using pretrained encoders (UNI). The large image is then progressively downsampled by a factor of 2, with patches at each scale paired with the SSL embeddings of all overlapping initial-scale patches. Then, the SSL embeddings and magnification level are fed to the Summarizer, which projects them into the cross-magnification Latent space. The diffusion model is trained to generate 256 × 256 patches conditioned on the Summarizer’s output.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="generation-results">Generation Results<a href="#generation-results" class="hash-link" aria-label="Direct link to Generation Results" title="Direct link to Generation Results">​</a></h2>
<div class="container text-center"><img src="/img/zoomldm/fid.png"></div>
<p>As indicated by the FID, ZoomLDM achieves superior performance across all magnifications compared to SoTA models. We see larger improvements for magnifications below 2.5x where the data scarcity severely impacts a model’s ability to synthesize diverse, high-quality images. By leveraging data and conditioning across all magnifications, we allow the low density data regions to benefit from the insights that the model gains from the entire dataset, improving both model performance and efficiency.</p>
<p><img decoding="async" loading="lazy" alt="patches" src="/assets/images/brca_patches-e4c1783bb685fcda03e1c4c075b8e443.png" width="1469" height="853" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="joint-multi-scale-generation">Joint Multi-Scale Generation<a href="#joint-multi-scale-generation" class="hash-link" aria-label="Direct link to Joint Multi-Scale Generation" title="Direct link to Joint Multi-Scale Generation">​</a></h2>
<p><img decoding="async" loading="lazy" alt="multi_scale_gen" src="/assets/images/multi_scale_examples_brca-188cc23bf7fb3543d028df308c7d4386.png" width="2318" height="674" class="img_ev3q"></p>
<p>We also introduce a joint sampling process that synthesizes images across two different scales. We jointly generate a 256×256 image at 1.25x and a 4096x4096 image at 20x, using the 1.25x generation to guide the global structure of the 20x image. Without this context each 20x patch is unaware of its surroundings and the generated image wouldn&#x27;t be globally coherent. With our approach, the generated large 20x image has a realistic global arrangement of cells and tissue. You can view more examples in our <a href="/pages/zoomldm_large_images/large_images.html" target="_blank">large image viewer</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="multi-scale-features">Multi-Scale Features<a href="#multi-scale-features" class="hash-link" aria-label="Direct link to Multi-Scale Features" title="Direct link to Multi-Scale Features">​</a></h2>
<div class="container text-center"><img src="/img/zoomldm/mil.png"></div>
<p>We utilize ZoomLDM as a feature extractor and apply an MIL approach for slide-level classification tasks of Breast cancer subtyping and Homologous Recombintion Deficiency (HRD) prediction. The results show that ZoomLDM’s multi-scale features (fusing 20x and 5x) outperform SoTA encoders in both tasks highlighting the effectiveness of ZoomLDM’s cross-magnification latent space in capturing multi-scale dependencies. Even in a single magnification, ZoomLD outperforms all SoTA encoders. We believe that by learning to synthesize images on top of the capabilities of the discriminative SSL encoders we can exceed previous models in representation learning.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="citation">Citation<a href="#citation" class="hash-link" aria-label="Direct link to Citation" title="Direct link to Citation">​</a></h2>
<div class="language-bibtex codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bibtex codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@InProceedings{Yellapragada_2025_CVPR,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  author = {Yellapragada, Srikar and Graikos, Alexandros and Triaridis, Kostas and Prasanna, Prateek and Gupta, Rajarsi and Saltz, Joel and Samaras, Dimitris},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  title = {ZoomLDM: Latent Diffusion Model for Multi-scale Image Generation},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  booktitle = {Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR)},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  month = {June},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  year = {2025},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  pages = {23453-23463}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/projects/pathae"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">PathAE - Pathology image compression with autoencoders</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/projects/gensis"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Gen-SIS - Generative augmentations for self-supervised learning</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#tldr" class="table-of-contents__link toc-highlight">TL;DR</a></li><li><a href="#model" class="table-of-contents__link toc-highlight">Model</a></li><li><a href="#generation-results" class="table-of-contents__link toc-highlight">Generation Results</a></li><li><a href="#joint-multi-scale-generation" class="table-of-contents__link toc-highlight">Joint Multi-Scale Generation</a></li><li><a href="#multi-scale-features" class="table-of-contents__link toc-highlight">Multi-Scale Features</a></li><li><a href="#citation" class="table-of-contents__link toc-highlight">Citation</a></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>